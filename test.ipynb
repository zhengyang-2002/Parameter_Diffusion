{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8aa0016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VAE ARCHITECTURE - Layer Names and Dimensions\n",
      "======================================================================\n",
      "\n",
      "ðŸ“¦ ENCODER\n",
      "----------------------------------------------------------------------\n",
      "encoder.fc_in.weight                               [2048, 513]               (1,050,624 params)\n",
      "encoder.fc_in.bias                                 [2048]                    (2,048 params)\n",
      "encoder.conv_in.weight                             [64, 10, 3, 3]            (5,760 params)\n",
      "encoder.conv_in.bias                               [64]                      (64 params)\n",
      "encoder.down.0.block.0.norm1.weight                [64]                      (64 params)\n",
      "encoder.down.0.block.0.norm1.bias                  [64]                      (64 params)\n",
      "encoder.down.0.block.0.conv1.weight                [64, 64, 3, 3]            (36,864 params)\n",
      "encoder.down.0.block.0.conv1.bias                  [64]                      (64 params)\n",
      "encoder.down.0.block.0.norm2.weight                [64]                      (64 params)\n",
      "encoder.down.0.block.0.norm2.bias                  [64]                      (64 params)\n",
      "encoder.down.0.block.0.conv2.weight                [64, 64, 3, 3]            (36,864 params)\n",
      "encoder.down.0.block.0.conv2.bias                  [64]                      (64 params)\n",
      "encoder.down.0.block.1.norm1.weight                [64]                      (64 params)\n",
      "encoder.down.0.block.1.norm1.bias                  [64]                      (64 params)\n",
      "encoder.down.0.block.1.conv1.weight                [64, 64, 3, 3]            (36,864 params)\n",
      "encoder.down.0.block.1.conv1.bias                  [64]                      (64 params)\n",
      "encoder.down.0.block.1.norm2.weight                [64]                      (64 params)\n",
      "encoder.down.0.block.1.norm2.bias                  [64]                      (64 params)\n",
      "encoder.down.0.block.1.conv2.weight                [64, 64, 3, 3]            (36,864 params)\n",
      "encoder.down.0.block.1.conv2.bias                  [64]                      (64 params)\n",
      "encoder.down.0.downsample.conv.weight              [64, 64, 3, 3]            (36,864 params)\n",
      "encoder.down.0.downsample.conv.bias                [64]                      (64 params)\n",
      "encoder.down.1.block.0.norm1.weight                [64]                      (64 params)\n",
      "encoder.down.1.block.0.norm1.bias                  [64]                      (64 params)\n",
      "encoder.down.1.block.0.conv1.weight                [128, 64, 3, 3]           (73,728 params)\n",
      "encoder.down.1.block.0.conv1.bias                  [128]                     (128 params)\n",
      "encoder.down.1.block.0.norm2.weight                [128]                     (128 params)\n",
      "encoder.down.1.block.0.norm2.bias                  [128]                     (128 params)\n",
      "encoder.down.1.block.0.conv2.weight                [128, 128, 3, 3]          (147,456 params)\n",
      "encoder.down.1.block.0.conv2.bias                  [128]                     (128 params)\n",
      "encoder.down.1.block.0.nin_shortcut.weight         [128, 64, 1, 1]           (8,192 params)\n",
      "encoder.down.1.block.0.nin_shortcut.bias           [128]                     (128 params)\n",
      "encoder.down.1.block.1.norm1.weight                [128]                     (128 params)\n",
      "encoder.down.1.block.1.norm1.bias                  [128]                     (128 params)\n",
      "encoder.down.1.block.1.conv1.weight                [128, 128, 3, 3]          (147,456 params)\n",
      "encoder.down.1.block.1.conv1.bias                  [128]                     (128 params)\n",
      "encoder.down.1.block.1.norm2.weight                [128]                     (128 params)\n",
      "encoder.down.1.block.1.norm2.bias                  [128]                     (128 params)\n",
      "encoder.down.1.block.1.conv2.weight                [128, 128, 3, 3]          (147,456 params)\n",
      "encoder.down.1.block.1.conv2.bias                  [128]                     (128 params)\n",
      "encoder.down.1.downsample.conv.weight              [128, 128, 3, 3]          (147,456 params)\n",
      "encoder.down.1.downsample.conv.bias                [128]                     (128 params)\n",
      "encoder.down.2.block.0.norm1.weight                [128]                     (128 params)\n",
      "encoder.down.2.block.0.norm1.bias                  [128]                     (128 params)\n",
      "encoder.down.2.block.0.conv1.weight                [256, 128, 3, 3]          (294,912 params)\n",
      "encoder.down.2.block.0.conv1.bias                  [256]                     (256 params)\n",
      "encoder.down.2.block.0.norm2.weight                [256]                     (256 params)\n",
      "encoder.down.2.block.0.norm2.bias                  [256]                     (256 params)\n",
      "encoder.down.2.block.0.conv2.weight                [256, 256, 3, 3]          (589,824 params)\n",
      "encoder.down.2.block.0.conv2.bias                  [256]                     (256 params)\n",
      "encoder.down.2.block.0.nin_shortcut.weight         [256, 128, 1, 1]          (32,768 params)\n",
      "encoder.down.2.block.0.nin_shortcut.bias           [256]                     (256 params)\n",
      "encoder.down.2.block.1.norm1.weight                [256]                     (256 params)\n",
      "encoder.down.2.block.1.norm1.bias                  [256]                     (256 params)\n",
      "encoder.down.2.block.1.conv1.weight                [256, 256, 3, 3]          (589,824 params)\n",
      "encoder.down.2.block.1.conv1.bias                  [256]                     (256 params)\n",
      "encoder.down.2.block.1.norm2.weight                [256]                     (256 params)\n",
      "encoder.down.2.block.1.norm2.bias                  [256]                     (256 params)\n",
      "encoder.down.2.block.1.conv2.weight                [256, 256, 3, 3]          (589,824 params)\n",
      "encoder.down.2.block.1.conv2.bias                  [256]                     (256 params)\n",
      "encoder.mid.block_1.norm1.weight                   [256]                     (256 params)\n",
      "encoder.mid.block_1.norm1.bias                     [256]                     (256 params)\n",
      "encoder.mid.block_1.conv1.weight                   [256, 256, 3, 3]          (589,824 params)\n",
      "encoder.mid.block_1.conv1.bias                     [256]                     (256 params)\n",
      "encoder.mid.block_1.norm2.weight                   [256]                     (256 params)\n",
      "encoder.mid.block_1.norm2.bias                     [256]                     (256 params)\n",
      "encoder.mid.block_1.conv2.weight                   [256, 256, 3, 3]          (589,824 params)\n",
      "encoder.mid.block_1.conv2.bias                     [256]                     (256 params)\n",
      "encoder.mid.attn_1.norm.weight                     [256]                     (256 params)\n",
      "encoder.mid.attn_1.norm.bias                       [256]                     (256 params)\n",
      "encoder.mid.attn_1.q.weight                        [256, 256, 1, 1]          (65,536 params)\n",
      "encoder.mid.attn_1.q.bias                          [256]                     (256 params)\n",
      "encoder.mid.attn_1.k.weight                        [256, 256, 1, 1]          (65,536 params)\n",
      "encoder.mid.attn_1.k.bias                          [256]                     (256 params)\n",
      "encoder.mid.attn_1.v.weight                        [256, 256, 1, 1]          (65,536 params)\n",
      "encoder.mid.attn_1.v.bias                          [256]                     (256 params)\n",
      "encoder.mid.attn_1.proj_out.weight                 [256, 256, 1, 1]          (65,536 params)\n",
      "encoder.mid.attn_1.proj_out.bias                   [256]                     (256 params)\n",
      "encoder.mid.block_2.norm1.weight                   [256]                     (256 params)\n",
      "encoder.mid.block_2.norm1.bias                     [256]                     (256 params)\n",
      "encoder.mid.block_2.conv1.weight                   [256, 256, 3, 3]          (589,824 params)\n",
      "encoder.mid.block_2.conv1.bias                     [256]                     (256 params)\n",
      "encoder.mid.block_2.norm2.weight                   [256]                     (256 params)\n",
      "encoder.mid.block_2.norm2.bias                     [256]                     (256 params)\n",
      "encoder.mid.block_2.conv2.weight                   [256, 256, 3, 3]          (589,824 params)\n",
      "encoder.mid.block_2.conv2.bias                     [256]                     (256 params)\n",
      "encoder.norm_out.weight                            [256]                     (256 params)\n",
      "encoder.norm_out.bias                              [256]                     (256 params)\n",
      "encoder.conv_out.weight                            [8, 256, 3, 3]            (18,432 params)\n",
      "encoder.conv_out.bias                              [8]                       (8 params)\n",
      "Total Encoder Parameters                           6,662,280\n",
      "\n",
      "ðŸ“¦ DECODER\n",
      "----------------------------------------------------------------------\n",
      "decoder.fc_out.weight                              [513, 2048]               (1,050,624 params)\n",
      "decoder.fc_out.bias                                [513]                     (513 params)\n",
      "decoder.conv_in.weight                             [256, 4, 3, 3]            (9,216 params)\n",
      "decoder.conv_in.bias                               [256]                     (256 params)\n",
      "decoder.mid.block_1.norm1.weight                   [256]                     (256 params)\n",
      "decoder.mid.block_1.norm1.bias                     [256]                     (256 params)\n",
      "decoder.mid.block_1.conv1.weight                   [256, 256, 3, 3]          (589,824 params)\n",
      "decoder.mid.block_1.conv1.bias                     [256]                     (256 params)\n",
      "decoder.mid.block_1.norm2.weight                   [256]                     (256 params)\n",
      "decoder.mid.block_1.norm2.bias                     [256]                     (256 params)\n",
      "decoder.mid.block_1.conv2.weight                   [256, 256, 3, 3]          (589,824 params)\n",
      "decoder.mid.block_1.conv2.bias                     [256]                     (256 params)\n",
      "decoder.mid.attn_1.norm.weight                     [256]                     (256 params)\n",
      "decoder.mid.attn_1.norm.bias                       [256]                     (256 params)\n",
      "decoder.mid.attn_1.q.weight                        [256, 256, 1, 1]          (65,536 params)\n",
      "decoder.mid.attn_1.q.bias                          [256]                     (256 params)\n",
      "decoder.mid.attn_1.k.weight                        [256, 256, 1, 1]          (65,536 params)\n",
      "decoder.mid.attn_1.k.bias                          [256]                     (256 params)\n",
      "decoder.mid.attn_1.v.weight                        [256, 256, 1, 1]          (65,536 params)\n",
      "decoder.mid.attn_1.v.bias                          [256]                     (256 params)\n",
      "decoder.mid.attn_1.proj_out.weight                 [256, 256, 1, 1]          (65,536 params)\n",
      "decoder.mid.attn_1.proj_out.bias                   [256]                     (256 params)\n",
      "decoder.mid.block_2.norm1.weight                   [256]                     (256 params)\n",
      "decoder.mid.block_2.norm1.bias                     [256]                     (256 params)\n",
      "decoder.mid.block_2.conv1.weight                   [256, 256, 3, 3]          (589,824 params)\n",
      "decoder.mid.block_2.conv1.bias                     [256]                     (256 params)\n",
      "decoder.mid.block_2.norm2.weight                   [256]                     (256 params)\n",
      "decoder.mid.block_2.norm2.bias                     [256]                     (256 params)\n",
      "decoder.mid.block_2.conv2.weight                   [256, 256, 3, 3]          (589,824 params)\n",
      "decoder.mid.block_2.conv2.bias                     [256]                     (256 params)\n",
      "decoder.up.0.block.0.norm1.weight                  [128]                     (128 params)\n",
      "decoder.up.0.block.0.norm1.bias                    [128]                     (128 params)\n",
      "decoder.up.0.block.0.conv1.weight                  [64, 128, 3, 3]           (73,728 params)\n",
      "decoder.up.0.block.0.conv1.bias                    [64]                      (64 params)\n",
      "decoder.up.0.block.0.norm2.weight                  [64]                      (64 params)\n",
      "decoder.up.0.block.0.norm2.bias                    [64]                      (64 params)\n",
      "decoder.up.0.block.0.conv2.weight                  [64, 64, 3, 3]            (36,864 params)\n",
      "decoder.up.0.block.0.conv2.bias                    [64]                      (64 params)\n",
      "decoder.up.0.block.0.nin_shortcut.weight           [64, 128, 1, 1]           (8,192 params)\n",
      "decoder.up.0.block.0.nin_shortcut.bias             [64]                      (64 params)\n",
      "decoder.up.0.block.1.norm1.weight                  [64]                      (64 params)\n",
      "decoder.up.0.block.1.norm1.bias                    [64]                      (64 params)\n",
      "decoder.up.0.block.1.conv1.weight                  [64, 64, 3, 3]            (36,864 params)\n",
      "decoder.up.0.block.1.conv1.bias                    [64]                      (64 params)\n",
      "decoder.up.0.block.1.norm2.weight                  [64]                      (64 params)\n",
      "decoder.up.0.block.1.norm2.bias                    [64]                      (64 params)\n",
      "decoder.up.0.block.1.conv2.weight                  [64, 64, 3, 3]            (36,864 params)\n",
      "decoder.up.0.block.1.conv2.bias                    [64]                      (64 params)\n",
      "decoder.up.0.block.2.norm1.weight                  [64]                      (64 params)\n",
      "decoder.up.0.block.2.norm1.bias                    [64]                      (64 params)\n",
      "decoder.up.0.block.2.conv1.weight                  [64, 64, 3, 3]            (36,864 params)\n",
      "decoder.up.0.block.2.conv1.bias                    [64]                      (64 params)\n",
      "decoder.up.0.block.2.norm2.weight                  [64]                      (64 params)\n",
      "decoder.up.0.block.2.norm2.bias                    [64]                      (64 params)\n",
      "decoder.up.0.block.2.conv2.weight                  [64, 64, 3, 3]            (36,864 params)\n",
      "decoder.up.0.block.2.conv2.bias                    [64]                      (64 params)\n",
      "decoder.up.1.block.0.norm1.weight                  [256]                     (256 params)\n",
      "decoder.up.1.block.0.norm1.bias                    [256]                     (256 params)\n",
      "decoder.up.1.block.0.conv1.weight                  [128, 256, 3, 3]          (294,912 params)\n",
      "decoder.up.1.block.0.conv1.bias                    [128]                     (128 params)\n",
      "decoder.up.1.block.0.norm2.weight                  [128]                     (128 params)\n",
      "decoder.up.1.block.0.norm2.bias                    [128]                     (128 params)\n",
      "decoder.up.1.block.0.conv2.weight                  [128, 128, 3, 3]          (147,456 params)\n",
      "decoder.up.1.block.0.conv2.bias                    [128]                     (128 params)\n",
      "decoder.up.1.block.0.nin_shortcut.weight           [128, 256, 1, 1]          (32,768 params)\n",
      "decoder.up.1.block.0.nin_shortcut.bias             [128]                     (128 params)\n",
      "decoder.up.1.block.1.norm1.weight                  [128]                     (128 params)\n",
      "decoder.up.1.block.1.norm1.bias                    [128]                     (128 params)\n",
      "decoder.up.1.block.1.conv1.weight                  [128, 128, 3, 3]          (147,456 params)\n",
      "decoder.up.1.block.1.conv1.bias                    [128]                     (128 params)\n",
      "decoder.up.1.block.1.norm2.weight                  [128]                     (128 params)\n",
      "decoder.up.1.block.1.norm2.bias                    [128]                     (128 params)\n",
      "decoder.up.1.block.1.conv2.weight                  [128, 128, 3, 3]          (147,456 params)\n",
      "decoder.up.1.block.1.conv2.bias                    [128]                     (128 params)\n",
      "decoder.up.1.block.2.norm1.weight                  [128]                     (128 params)\n",
      "decoder.up.1.block.2.norm1.bias                    [128]                     (128 params)\n",
      "decoder.up.1.block.2.conv1.weight                  [128, 128, 3, 3]          (147,456 params)\n",
      "decoder.up.1.block.2.conv1.bias                    [128]                     (128 params)\n",
      "decoder.up.1.block.2.norm2.weight                  [128]                     (128 params)\n",
      "decoder.up.1.block.2.norm2.bias                    [128]                     (128 params)\n",
      "decoder.up.1.block.2.conv2.weight                  [128, 128, 3, 3]          (147,456 params)\n",
      "decoder.up.1.block.2.conv2.bias                    [128]                     (128 params)\n",
      "decoder.up.1.upsample.conv.weight                  [128, 128, 3, 3]          (147,456 params)\n",
      "decoder.up.1.upsample.conv.bias                    [128]                     (128 params)\n",
      "decoder.up.2.block.0.norm1.weight                  [256]                     (256 params)\n",
      "decoder.up.2.block.0.norm1.bias                    [256]                     (256 params)\n",
      "decoder.up.2.block.0.conv1.weight                  [256, 256, 3, 3]          (589,824 params)\n",
      "decoder.up.2.block.0.conv1.bias                    [256]                     (256 params)\n",
      "decoder.up.2.block.0.norm2.weight                  [256]                     (256 params)\n",
      "decoder.up.2.block.0.norm2.bias                    [256]                     (256 params)\n",
      "decoder.up.2.block.0.conv2.weight                  [256, 256, 3, 3]          (589,824 params)\n",
      "decoder.up.2.block.0.conv2.bias                    [256]                     (256 params)\n",
      "decoder.up.2.block.1.norm1.weight                  [256]                     (256 params)\n",
      "decoder.up.2.block.1.norm1.bias                    [256]                     (256 params)\n",
      "decoder.up.2.block.1.conv1.weight                  [256, 256, 3, 3]          (589,824 params)\n",
      "decoder.up.2.block.1.conv1.bias                    [256]                     (256 params)\n",
      "decoder.up.2.block.1.norm2.weight                  [256]                     (256 params)\n",
      "decoder.up.2.block.1.norm2.bias                    [256]                     (256 params)\n",
      "decoder.up.2.block.1.conv2.weight                  [256, 256, 3, 3]          (589,824 params)\n",
      "decoder.up.2.block.1.conv2.bias                    [256]                     (256 params)\n",
      "decoder.up.2.block.2.norm1.weight                  [256]                     (256 params)\n",
      "decoder.up.2.block.2.norm1.bias                    [256]                     (256 params)\n",
      "decoder.up.2.block.2.conv1.weight                  [256, 256, 3, 3]          (589,824 params)\n",
      "decoder.up.2.block.2.conv1.bias                    [256]                     (256 params)\n",
      "decoder.up.2.block.2.norm2.weight                  [256]                     (256 params)\n",
      "decoder.up.2.block.2.norm2.bias                    [256]                     (256 params)\n",
      "decoder.up.2.block.2.conv2.weight                  [256, 256, 3, 3]          (589,824 params)\n",
      "decoder.up.2.block.2.conv2.bias                    [256]                     (256 params)\n",
      "decoder.up.2.upsample.conv.weight                  [256, 256, 3, 3]          (589,824 params)\n",
      "decoder.up.2.upsample.conv.bias                    [256]                     (256 params)\n",
      "decoder.norm_out.weight                            [64]                      (64 params)\n",
      "decoder.norm_out.bias                              [64]                      (64 params)\n",
      "decoder.conv_out.weight                            [10, 64, 3, 3]            (5,760 params)\n",
      "decoder.conv_out.bias                              [10]                      (10 params)\n",
      "Total Decoder Parameters                           9,309,003\n",
      "\n",
      "ðŸ“¦ OTHER (Quantization Layers)\n",
      "----------------------------------------------------------------------\n",
      "loss.logvar                                        []                        (1 params)\n",
      "quant_conv.weight                                  [8, 8, 1, 1]              (64 params)\n",
      "quant_conv.bias                                    [8]                       (8 params)\n",
      "post_quant_conv.weight                             [4, 4, 1, 1]              (16 params)\n",
      "post_quant_conv.bias                               [4]                       (4 params)\n",
      "Total Other Parameters                             93\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Total Parameters: 15,971,376\n",
      "\n",
      "Input Dimension:  513\n",
      "Output Dimension: 513\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the VAE checkpoint\n",
    "ckpt = torch.load('./Pretrained_Components/VAE', map_location='cpu', weights_only=False)\n",
    "sd = ckpt['state_dict']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"VAE ARCHITECTURE - Layer Names and Dimensions\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Group by encoder/decoder\n",
    "encoder_layers = {}\n",
    "decoder_layers = {}\n",
    "other_layers = {}\n",
    "\n",
    "for name, param in sd.items():\n",
    "    shape_str = str(list(param.shape))\n",
    "    numel = param.numel()\n",
    "    \n",
    "    if name.startswith('encoder'):\n",
    "        encoder_layers[name] = (shape_str, numel)\n",
    "    elif name.startswith('decoder'):\n",
    "        decoder_layers[name] = (shape_str, numel)\n",
    "    else:\n",
    "        other_layers[name] = (shape_str, numel)\n",
    "\n",
    "# Print Encoder\n",
    "print(\"\\nðŸ“¦ ENCODER\")\n",
    "print(\"-\" * 70)\n",
    "total_encoder = 0\n",
    "for name, (shape, numel) in encoder_layers.items():\n",
    "    print(f\"{name:50s} {shape:25s} ({numel:,} params)\")\n",
    "    total_encoder += numel\n",
    "print(f\"{'Total Encoder Parameters':50s} {total_encoder:,}\")\n",
    "\n",
    "# Print Decoder\n",
    "print(\"\\nðŸ“¦ DECODER\")\n",
    "print(\"-\" * 70)\n",
    "total_decoder = 0\n",
    "for name, (shape, numel) in decoder_layers.items():\n",
    "    print(f\"{name:50s} {shape:25s} ({numel:,} params)\")\n",
    "    total_decoder += numel\n",
    "print(f\"{'Total Decoder Parameters':50s} {total_decoder:,}\")\n",
    "\n",
    "# Print Other (quant_conv, post_quant_conv)\n",
    "if other_layers:\n",
    "    print(\"\\nðŸ“¦ OTHER (Quantization Layers)\")\n",
    "    print(\"-\" * 70)\n",
    "    total_other = 0\n",
    "    for name, (shape, numel) in other_layers.items():\n",
    "        print(f\"{name:50s} {shape:25s} ({numel:,} params)\")\n",
    "        total_other += numel\n",
    "    print(f\"{'Total Other Parameters':50s} {total_other:,}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "total_params = sum(p.numel() for p in sd.values())\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"\\nInput Dimension:  {sd['encoder.fc_in.weight'].shape[1]}\")\n",
    "print(f\"Output Dimension: {sd['decoder.fc_out.weight'].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b43d4830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating model (this should succeed) ===\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "Working with z of shape (1, 4, 16, 16) = 1024 dimensions.\n",
      "making attention of type 'vanilla' with 256 in_channels\n",
      "Model created successfully!\n",
      "=== Trying forward pass (this will fail) ===\n",
      "Input: torch.Size([1, 5130])\n",
      "Forward pass succeeded!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, './External/DNNWG')\n",
    "\n",
    "from stage1.models.autoencoder import VAENoDiscModel\n",
    "\n",
    "ddconfig = {\n",
    "    'double_z': True,\n",
    "    'z_channels': 4,\n",
    "    'resolution': 64,\n",
    "    'in_channels': 10,\n",
    "    'my_channels': 10,\n",
    "    'out_ch': 10,\n",
    "    'ch': 64,\n",
    "    'ch_mult': [1, 2, 4],\n",
    "    'num_res_blocks': 2,\n",
    "    'attn_resolutions': [],\n",
    "    'dropout': 0.0,\n",
    "    'in_dim': 513,\n",
    "    'fdim': 4096\n",
    "}\n",
    "\n",
    "lossconfig = {\n",
    "    'target': 'stage1.modules.losses.CustomLosses.Myloss',\n",
    "    'params': {'logvar_init': 0.0, 'kl_weight': 1e-6}\n",
    "}\n",
    "\n",
    "print('=== Creating model (this should succeed) ===')\n",
    "model = VAENoDiscModel(\n",
    "    ddconfig=ddconfig,\n",
    "    lossconfig=lossconfig,\n",
    "    embed_dim=4,\n",
    "    learning_rate=1e-4,\n",
    "    input_key='weight',\n",
    "    device='cpu'\n",
    ")\n",
    "print('Model created successfully!')\n",
    "\n",
    "print('=== Trying forward pass (this will fail) ===')\n",
    "x = torch.randn(1, 5130)\n",
    "print(f'Input: {x.shape}')\n",
    "\n",
    "try:\n",
    "    output = model({'weight': x})\n",
    "    print('Forward pass succeeded!')\n",
    "except Exception as e:\n",
    "    print(f'Forward pass FAILED: {e}')\n",
    "    print()\n",
    "    print('This means:')\n",
    "    print('  - Model can be CREATED (no error)')\n",
    "    print('  - Model CANNOT be TRAINED (forward pass fails)')\n",
    "    print('  - Your friend could NOT have trained this successfully!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707eaa5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "param_diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
